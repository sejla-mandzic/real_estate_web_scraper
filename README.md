# Web scraper for olx.ba real estate
This is the project that help users scrape real estate data from popular web shop olx.ba. The main focus is on houses and apartments, but this can easely be extended to any data. Programs scrape the site, format data and convert it to csv files. 

## Installation of the project
To install the project on local machine, you can use either batch or bash script, depending on your system. You can find these scripts at the root directory of the project.

## Using the scrapers
There are several scrapers in the project, each one dedicated to scraping a specific piece of data from the olx.ba

### URL scrapers
In the directory "url_scrapers" you can find two scrapers, active and closed. 
* Active scraper scrapes apartments and houses that are currently listed as available on the olx.ba. If you want to use active scraper, you just need to visit olx.ba, enter some additional filter (optional) and let scraper get you the URLs of all the houses and apartments it was able to scrape. You need to set variable APARTMENTS_URL and HOUSES_URL, or you can use the one I already set in the "common/config.py" file. 
* Closed scraper scrapes the listings that were sold or closed for some other reason. In order to do this, you will have to manually go to the profile of the company/person that is the owner of the listings, visit "Zavr≈°eni oglasi" tab. There, using console (fn_key + F12) you can get an URL for API of the user items. Set that variable in "common/config.py" and also set the number of pages. 
Whichever scraper you use, it will generate text file in the root directory, that will be used by the data scrapers to get data for every real estate in the file. 
#### NOTE: 
In the file "common/config.py" there are hardcoded variables for the number of pages per canton for apartments and houses. You can manipulate this number based on your preferences. Just keep in mind that for some reason, olx.ba won't load pages greater that 50. 

### Data scrapers
In the directory "data_scrapers" there are scrapers for apartments and houses. As previously mentioned, data scrapers will use apartments.txt and houses.txt files generated by the URL scrapers to scrape data based on every item in those files. The result of data scrapers are CSV files with well-formatted entries that hold information about the real estate. Data scrapers also do character checks, to avoid characters that will break the CSV file. 